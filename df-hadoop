FROM docker.io/rubigdata/base:buildx-latest AS build
MAINTAINER Arjen P. de Vries <arjen@acm.org>

## Basic tools:

USER root:root

# Versions to install:
ENV HADOOP_VER="3.2.2"

## Hadoop
#
COPY dist/hadoop-${HADOOP_VER}.tar.gz /tmp
RUN echo "Building Hadoop" \
 && tar -xzf /tmp/hadoop-${HADOOP_VER}.tar.gz \
 && rm /tmp/hadoop-${HADOOP_VER}.tar.gz \
 && cd /hadoop-${HADOOP_VER} \ 
 && mkdir -p share/course \ 
 && echo "export JAVA_HOME=${JAVA_HOME}" >> etc/hadoop/hadoop-env.sh \
 && echo "export HADOOP_CLASSPATH=${JAVA_HOME}/lib/tools.jar" >> etc/hadoop/hadoop-env.sh \
 && echo "export HADOOP_HOME=/opt/hadoop" >> etc/hadoop/hadoop-env.sh \
 && echo "export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop" >> etc/hadoop/hadoop-env.sh \
 && bash -c 'for ev in HDFS_NAMENODE HDFS_DATANODE HDFS_SECONDARYNAMENODE YARN_RESOURCEMANAGER YARN_NODEMANAGER ; \
   do \
     echo export ${ev}_USER=hadoop ; \
   done >> etc/hadoop/hadoop-env.sh'

## Patch Hadoop for bash 4.4
#
COPY HADOOP-16167.004.patch /tmp
RUN echo "Bash patch HADOOP-16167.004" \
 && $microdnf install patch \
 && cd /hadoop-${HADOOP_VER}/libexec \
 && patch -i /tmp/HADOOP-16167.004.patch

#########################################################
#########################################################

## Stage 2
#
FROM docker.io/rubigdata/sshd:buildx-latest

USER root:root

## Add user hadoop
#
ENV HADOOP_GID=1000
ENV HADOOP_UID=1000

RUN --mount=type=secret,id=rubigdatapass PASS=$(cat /run/secrets/rubigdatapass) \
 && echo "Setting up Hadoop user" \
 && groupadd -r -g ${HADOOP_GID} hadoop \
 && useradd -r -m -u ${HADOOP_UID} -g ${HADOOP_GID} -d /opt/hadoop hadoop \
 && echo $PASS | passwd --stdin hadoop \
 && usermod -aG wheel hadoop \
 && echo "%hadoop ALL = NOPASSWD: /opt/ssh/sbin/sshd" > /etc/sudoers.d/hadoop
 
## Tini
#
#COPY --from=docker.io/rubigdata/tini:buildx-latest /tmp/tini.rpm /tmp

#RUN set -eux \
# && rpm -i /tmp/tini.rpm \
# && rm /tmp/tini.rpm \
# && tini --version

## Hadoop

USER hadoop:hadoop

ENV HADOOP_VER="3.2.2"
ENV HADOOP_HOME /opt/hadoop

COPY --chown=hadoop:hadoop --from=build /hadoop-${HADOOP_VER} ${HADOOP_HOME}

## Hadoop settings

COPY --chown=hadoop:hadoop \
  core-site.xml \
  hdfs-site.xml \
  mapred-site.xml \
  yarn-site.xml \
  $HADOOP_HOME/etc/hadoop/

COPY --chown=hadoop:hadoop \
  WordCount.java $HADOOP_HOME/share/course/

## Setup environment

ENV PATH $PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

## Environment
# TODO: Check which ones are needed
#       Check if these persist
#
ENV HADOOP_COMMON_HOME $HADOOP_HOME
ENV HADOOP_HDFS_HOME $HADOOP_HOME
ENV HADOOP_MAPRED_HOME $HADOOP_HOME
ENV HADOOP_YARN_HOME $HADOOP_HOME
ENV HADOOP_CONF_DIR $HADOOP_HOME/etc/hadoop

## SSH setup

RUN echo Configure SSH for user hadoop... \
 && /opt/ssh/bin/ssh-keygen -t rsa -P '' -f ${HOME}/.ssh/id_rsa \
 && cat ${HOME}/.ssh/id_rsa.pub >> ${HOME}/.ssh/authorized_keys \
 && chmod 0600 ${HOME}/.ssh/authorized_keys                     \ 
 && echo localhost $(cat /etc/ssh/ssh_host_rsa_key.pub) >> ${HOME}/.ssh/known_hosts \
 && echo 0.0.0.0   $(cat /etc/ssh/ssh_host_rsa_key.pub) >> ${HOME}/.ssh/known_hosts \
 && echo Prepare ${HOME}/.bashrc \
 && echo export PATH=${PATH}:/opt/ssh/bin >> ${HOME}/.bashrc \
 && echo '[ ! -f /var/run/sshd.pid ] && sudo /opt/ssh/sbin/sshd > /dev/null' >> ${HOME}/.bashrc \
 && echo export JAVA_HOME=${JAVA_HOME} >> ${HOME}/.bashrc \
 && echo . /opt/hadoop/etc/hadoop/hadoop-env.sh >> ${HOME}/.bashrc

EXPOSE 9870
EXPOSE 8088

WORKDIR /opt/hadoop

# Use default entrypoint instead of older:
#ENTRYPOINT [ "/usr/bin/tini", "--" ]
#CMD ["/bin/bash"]
