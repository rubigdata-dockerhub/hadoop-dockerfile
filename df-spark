FROM docker.io/rubigdata/base:buildx-latest AS build
MAINTAINER Arjen P. de Vries <arjen@acm.org>

ENV SPARK_VER="3.5.5"
ENV SPARK_BIN_VER="3.5.5-bin-without-hadoop"
ENV Z_VERSION="0.12.0"

USER root:root

COPY dist/spark-${SPARK_BIN_VER}.tgz /tmp
RUN echo "Download Spark binary" && \
  tar -xzf /tmp/spark-${SPARK_BIN_VER}.tgz && \
  rm /tmp/spark-${SPARK_BIN_VER}.tgz

COPY dist/zeppelin-${Z_VERSION}-bin-netinst.tgz /tmp
RUN echo "Download Zeppelin binary" && \
  tar -zxf /tmp/zeppelin-${Z_VERSION}-bin-netinst.tgz && \
  rm /tmp/zeppelin-${Z_VERSION}-bin-netinst.tgz

#########################################################
#########################################################

## Stage 2
#
FROM docker.io/rubigdata/hadoop:buildx-latest

USER hadoop:hadoop

ENV SPARK_VER="3.5.5"
ENV SPARK_BIN_VER="3.5.5-bin-without-hadoop"
ENV Z_VERSION="0.12.0"

## Spark

ENV SPARK_HOME="/opt/spark"  
ENV PATH="$SPARK_HOME/bin:$PATH"

COPY --chown=hadoop:hadoop --from=build /spark-${SPARK_BIN_VER} ${SPARK_HOME}

RUN echo Prepare ${HOME}/.bashrc \
 && echo export PATH="$SPARK_HOME/bin:$PATH" >> ${HOME}/.bashrc \
 && echo export SPARK_DIST_CLASSPATH=$(hadoop classpath) >> ${HOME}/.bashrc

## Zeppelin

ENV ZEPPELIN_HOME=/opt/zeppelin

COPY --chown=hadoop:hadoop --from=build /zeppelin-${Z_VERSION}-bin-netinst ${ZEPPELIN_HOME}

## Not sure if all of the following is still necessary, it was created this way for the 2019 course...
##
##    mkdir -p ${Z_HOME}/logs ${Z_HOME}/run ${Z_HOME}/webapps && \
##    # Allow process to edit /etc/passwd, to create a user entry for zeppelin
##    chgrp root /etc/passwd && chmod ug+rw /etc/passwd && \
##    # Give access to some specific folders
##    chmod -R 775 "${Z_HOME}/logs" "${Z_HOME}/run" "${Z_HOME}/notebook" "${Z_HOME}/conf" && \
##    # Allow process to create new folders (e.g. webapps)
##    chmod 775 ${Z_HOME}

## Config settings:
## SPARK_HOME in zeppelin-env.sh
## HADOOP_CONF_DIR in zeppelin-env.sh
## Spark spark.master as yarn-client in Zeppelin Interpreters setting page
## Set USE_HADOOP as true in zeppelin-env.sh

COPY --chown=hadoop:hadoop \
  zeppelin-env.sh \
  zeppelin-site.xml \
  log4j.properties \
  interpreter.json \
  ${ZEPPELIN_HOME}/conf/

EXPOSE 4040
EXPOSE 8080
EXPOSE 9001

WORKDIR /
# No longer use tini
# ENTRYPOINT [ "/usr/bin/tini", "--" ]
ENTRYPOINT ["/bin/bash", "-c", ". /opt/hadoop/.bashrc ; /opt/zeppelin/bin/zeppelin.sh"]

