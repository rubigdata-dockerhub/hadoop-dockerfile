FROM docker.io/rubigdata/spark:buildx-latest
MAINTAINER Arjen P. de Vries <arjen@acm.org>

USER root:root

## Ideally I'd overwrite /etc/hosts but doesn't seem to work
## Need indirection in startup script to achieve this
COPY \
  add-to-hosts.sh \
  redbad-setup/hosts \
  /root/

## SBT & add-to-hosts-sh
RUN echo Prepare SBT \
 && $wget -O /etc/yum.repos.d/sbt-rpm.repo https://www.scala-sbt.org/sbt-rpm.repo \
 && $microdnf install sbt \
 && echo "Add to hosts" file setup \
 && chmod 755 /root/add-to-hosts.sh \
 && echo "%hadoop ALL = NOPASSWD: /root/add-to-hosts.sh" >> /etc/sudoers.d/hadoop

USER hadoop:hadoop

## Note: the use of ADD on a local tar archive unpacks it automatically

ADD --chown=hadoop:hadoop rubigdata.tgz /opt/hadoop/

## TODO: copy files from redbad-setup

COPY --chown=hadoop:hadoop \
  redbad-setup/hadoop-conf/core-site.xml \
  redbad-setup/hadoop-conf/hdfs-site.xml \
  redbad-setup/hadoop-conf/mapred-site.xml \
  redbad-setup/hadoop-conf/yarn-site.xml \
  redbad-setup/hadoop-conf/capacity-scheduler.xml \
  redbad-setup/hadoop-conf/workers \
  $HADOOP_HOME/etc/hadoop/

COPY --chown=hadoop:hadoop \
  redbad-setup/spark-conf/spark-defaults.conf \
  redbad-setup/spark-conf/spark-env.sh \
  redbad-setup/spark-conf/workers \
  $SPARK_HOME/conf/

RUN echo Update JAVA_HOME from cluster Spark env \
 && echo export JAVA_HOME=/etc/alternatives/java_sdk_1.8.0 | tee -a /opt/spark/conf/spark-env.sh > /dev/null

## Inherit CMD etc from spark, but use different working directory:

WORKDIR /opt/hadoop/rubigdata

## Note: the exec is important to propagate the signals send by docker stop
ENTRYPOINT ["/bin/bash", "-c", "sudo /root/add-to-hosts.sh ; exec bash"]
