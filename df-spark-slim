FROM docker.io/rubigdata/base:buildx-latest AS build
MAINTAINER Arjen P. de Vries <arjen@acm.org>

ENV SPARK_VER="3.1.1"
ENV SPARK_BIN_VER="3.1.1-bin-hadoop3.2"
ENV Z_VERSION="0.9.0"

USER root:root

COPY dist/spark-${SPARK_BIN_VER}.tgz /tmp
RUN echo "Download Spark binary" && \
  tar -xzf /tmp/spark-${SPARK_BIN_VER}.tgz && \
  rm /tmp/spark-${SPARK_BIN_VER}.tgz

COPY dist/zeppelin-${Z_VERSION}-bin-netinst.tgz /tmp
RUN echo "Download Zeppelin binary" && \
  tar -zxf /tmp/zeppelin-${Z_VERSION}-bin-netinst.tgz && \
  rm /tmp/zeppelin-${Z_VERSION}-bin-netinst.tgz

#########################################################
#########################################################

## Stage 2
#
FROM docker.io/rubigdata/base:buildx-latest

## Add user hadoop
#
ENV HADOOP_GID=1000
ENV HADOOP_UID=1000

RUN --mount=type=secret,id=rubigdatapass PASS=$(cat /run/secrets/rubigdatapass) \
 && echo "Setting up Hadoop user" \
 && groupadd -r -g ${HADOOP_GID} hadoop \
 && useradd -r -m -u ${HADOOP_UID} -g ${HADOOP_GID} -d /opt/hadoop hadoop \
 && echo $PASS | passwd --stdin hadoop \
 && usermod -aG wheel hadoop \
 && echo "%hadoop ALL = NOPASSWD: /opt/ssh/sbin/sshd" > /etc/sudoers.d/hadoop
 
## Tini
#
#COPY --from=docker.io/rubigdata/tini:buildx-latest /tmp/tini.rpm /tmp
#
#RUN set -eux \
# && rpm -i /tmp/tini.rpm \
# && rm /tmp/tini.rpm \
# && tini --version

USER hadoop:hadoop

ENV SPARK_VER="3.1.1"
ENV SPARK_BIN_VER="3.1.1-bin-hadoop3.2"
ENV Z_VERSION="0.9.0"

## Spark

ENV SPARK_HOME="/opt/spark"  
ENV PATH="$SPARK_HOME/bin:$PATH"

COPY --chown=hadoop:hadoop --from=build /spark-${SPARK_BIN_VER} ${SPARK_HOME}

RUN echo Prepare ${HOME}/.bashrc \
 && echo export PATH="$SPARK_HOME/bin:$PATH" >> ${HOME}/.bashrc

## Zeppelin

ENV ZEPPELIN_HOME=/opt/zeppelin

COPY --chown=hadoop:hadoop --from=build /zeppelin-${Z_VERSION}-bin-netinst ${ZEPPELIN_HOME}

## Not sure if all of the following is still necessary, it was created this way for the 2019 course...
##
##    mkdir -p ${Z_HOME}/logs ${Z_HOME}/run ${Z_HOME}/webapps && \
##    # Allow process to edit /etc/passwd, to create a user entry for zeppelin
##    chgrp root /etc/passwd && chmod ug+rw /etc/passwd && \
##    # Give access to some specific folders
##    chmod -R 775 "${Z_HOME}/logs" "${Z_HOME}/run" "${Z_HOME}/notebook" "${Z_HOME}/conf" && \
##    # Allow process to create new folders (e.g. webapps)
##    chmod 775 ${Z_HOME}

## Config settings:
## SPARK_HOME in zeppelin-env.sh
## HADOOP_CONF_DIR in zeppelin-env.sh
## Spark spark.master as yarn-client in Zeppelin Interpreters setting page
## Set USE_HADOOP as true in zeppelin-env.sh

COPY --chown=hadoop:hadoop \
  zeppelin-env.sh \
  zeppelin-site.xml \
  log4j.properties \
  interpreter.json \
  ${ZEPPELIN_HOME}/conf/

EXPOSE 4040
EXPOSE 8080
EXPOSE 9001

WORKDIR /
#ENTRYPOINT [ "/usr/bin/tini", "--" ]
ENTRYPOINT ["/bin/bash", "-c", ". /opt/hadoop/.bashrc ; /opt/zeppelin/bin/zeppelin.sh"]
